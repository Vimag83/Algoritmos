@INPROCEEDINGS{11052817,
  author={Treude, Christoph and Gerosa, Marco A.},
  booktitle={2025 IEEE/ACM Second International Conference on AI Foundation Models and Software Engineering (Forge)}, 
  title={How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={236-240},
  abstract={Artificial intelligence (AI), including large language models and generative AI, is emerging as a significant force in software development, offering developers powerful tools that span the entire development lifecycle. Although software engineering research has extensively studied AI tools in software development, the specific types of interactions between developers and these AI-powered tools have only recently begun to receive attention. Understanding and improving these interactions has the potential to enhance productivity, trust, and efficiency in AI-driven workflows. In this paper, we propose a taxonomy of interaction types between developers and AI tools, identifying eleven distinct interaction types, such as auto-complete code suggestions, command-driven actions, and conversational assistance. Building on this taxonomy, we outline a research agenda focused on optimizing AI interactions, improving developer control, and addressing trust and usability challenges in AI-assisted development. By establishing a structured foundation for studying developer-AI interactions, this paper aims to stimulate research on creating more effective, adaptive AI tools for software development.},
  keywords={Productivity;Systematics;Generative AI;Large language models;Taxonomy;Refining;Artificial intelligence;Usability;Software engineering;Software development management;Artificial Intelligence;Software Development;Developer Tools;Human-AI Interaction;Generative AI;Large Language Models},
  doi={10.1109/Forge66646.2025.00033},
  ISSN={},
  month={April},}@INPROCEEDINGS{10392804,
  author={Han, Ji-Won and Lee, Yeon-Joon},
  booktitle={2023 14th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Generative AI for Radiological Image Data: Current Trends and Outlook}, 
  year={2023},
  volume={},
  number={},
  pages={143-147},
  abstract={Generative artificial intelligence (AI) has gained prominence, particularly in the field of radiological image data. This study investigates current trends and prospects of generative AI in X-ray, CT, MRI, and PET imaging. Emphasizing the importance of data quantity and quality, we ensure reliable and useful outputs. Given the significance of ethical dimensions in generative AI for radiological imaging, ethical considerations are also addressed. By analyzing recent advancements, this study offers insights into the evolution of generative AI in radiological image data and future directions.},
  keywords={Ethics;Privacy;Generative AI;Magnetic resonance imaging;Medical services;Radiology;Market research;Generative AI;GAN;X-ray;CT;MRI;PET},
  doi={10.1109/ICTC58733.2023.10392804},
  ISSN={2162-1241},
  month={Oct},}@INPROCEEDINGS{10375472,
  author={Pasupuleti, Rajesh and Vadapalli, Ravi and Mader, Christopher},
  booktitle={2023 Tenth International Conference on Social Networks Analysis, Management and Security (SNAMS)}, 
  title={Cyber Security Issues and Challenges Related to Generative AI and ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, Generative Artificial Intelligence (AI) and ChatGPT (Generative Pre-trained Transformer) models that are capable of generating realistic human-mimicked languages have gained progressive popularity. With the evolution of technology, there has been a significant increase in the availability and usage of artificial intelligence tools, such as ChatGPT and Generative AI, that will assist in shaping the future. However, this increasing popularity poses a potential risk if used inappropriately. Threats from AI pose special challenges for government, the private sector, and national security. In this paper, we address some of key concerns of significant cyber security issues and challenges related to Generative AI and ChatGPT. With careful consideration to application usage, organizations can implement appropriate security measures to mitigate these risks. We also incorporate recommendations about ChatGPT usage and its impact on society. It is important that researchers, developers, and policymakers (CIOs, CSOs) work together to mitigate these risks and to ensure that these models are used in a responsible and ethical manner.},
  keywords={Ethics;Analytical models;Social networking (online);Government;Chatbots;Transformers;Artificial intelligence;Cybersecurity Issues;Challenges;Generative AI;ChatGPT;LLM Models;Risks},
  doi={10.1109/SNAMS60348.2023.10375472},
  ISSN={2831-7343},
  month={Nov},}@ARTICLE{10254249,
  author={Sai, Siva and Garg, Akshat and Jhawar, Kartik and Chamola, Vinay and Sikdar, Biplab},
  journal={IEEE Open Journal of Vehicular Technology}, 
  title={A Comprehensive Survey on Artificial Intelligence for Unmanned Aerial Vehicles}, 
  year={2023},
  volume={4},
  number={},
  pages={713-738},
  abstract={Artificial Intelligence (AI) is an emerging technology that finds its application in various industries. Integration of AI in Unmanned Aerial Vehicles (UAVs) can lead to tremendous growth in the field of UAVs by improving flight safety and efficiency. Machine learning algorithms can enable UAVs to make real-time decisions in complex environments and reach the optimal solution that aims to fulfill a mission's requirements within the hardware constraints such as battery and payload. Several recent works in UAVs employed a variety of machine learning algorithms to enhance the capabilities of UAVs and assist them. Although several reviews have been published examining the various aspects of AI for UAVs, they are all pertaining to particular applications or technologies. Addressing this research gap, we present a comprehensive and diversified review to enable researchers to analyze the current and future requirements and develop the latest solutions utilizing AI. We have classified the reviewed works based on three different classification schemes: 1) application scenario-based, 2) AI algorithm-based, and 3) AI training paradigm-based. We have also presented a compilation of frameworks, tools, and libraries used in AI-integrated UAV systems. We identified that the integration of AI in UAVs has a wide array of applications ranging from path planning to resource allocation. We have observed that Reinforcement Learning based algorithms are more often used in AI-integrated UAV systems than other AI algorithms. Further, our findings reveal that UAV frameworks employing federated learning and other distributed machine learning paradigms are quickly emerging. Furthermore, we also have put forth several challenges and potential applications of AI-integrated UAV systems.},
  keywords={Artificial intelligence;Autonomous aerial vehicles;Machine learning algorithms;Sensors;UAVs;machine learning;artificial intelligence;applications;AI algorithms;AI training paradigms},
  doi={10.1109/OJVT.2023.3316181},
  ISSN={2644-1330},
  month={},}@INPROCEEDINGS{11022288,
  author={Baig, Mirza Abdul Aleem and Li, Shibo},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={AI-powered Human-on-Chip: Redefining Biomedical Frontiers}, 
  year={2024},
  volume={},
  number={},
  pages={297-306},
  abstract={Human-on-chip technology heralds a transformative paradigm in biomedical frontiers, furnishing diminutive replicas of human organs and tissues on microscale substrates. These platforms offer an unprecedented avenue for scrutinizing human physiology, diseases, and pharmacological responses with heightened precision, efficiency, and ethical consideration vis-a-vis conventional methodologies, contributing to the achievement of the Sustainable Development Goal (SDG) related to good health and well-being (SDG-03). This perspective explores the integration of human-on-chip technology with artificial intelligence (AI) to enhance the efficacy of these systems. AI algorithms assume a pivotal function in deciphering intricate datasets emanating from human-on-chip experiments, prognosticating outcomes, fine-tuning experimental parameters, and even orchestrating chip operations. This investigation illuminates the contemporary state-of-the-art human-on-chip technology, the critical role of AI in propelling this domain forward, and the prospective synergy between these innovations in the biomedical frontiers, thereby contributing to the advancement of health-related sustainable development goals.},
  keywords={Ethics;Technological innovation;Accuracy;Biological systems;Propulsion;Physiology;Artificial intelligence;Sustainable development;Substrates;Diseases;Human-on-Chip;Artificial Intelligence;Biomedical Frontiers;Sustainable Development Goals},
  doi={10.1109/ACAIT63902.2024.11022288},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11077549,
  author={Arora, Sunil and Manral, Vishwas and S, Dupali and Chakraborty, Parthasarathi},
  booktitle={2025 6th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={AI, Privacy, and Data Leakage: A Study of Current DLP Shortcomings}, 
  year={2025},
  volume={},
  number={},
  pages={269-273},
  abstract={Artificial intelligence (AI) systems have transformed data processing, but they raise serious privacy concerns about data leakage and the unauthorized exposure of sensitive personal information. As AI models are increasingly deployed across various industries to process and analyze personal data, understanding the role of Data Leakage Prevention (DLP) tools in securing AI applications and data is critical. Traditional DLP tools that rely on static, rule-based controls are ineffective in handling dynamic and complex data flows within AI environments, especially with synthetic data usage. This paper explores the challenges of DLP solutions in the AI environment, particularly with synthetic data usage and the need for a modernized approach to DLP solutions.},
  keywords={Training;Analytical models;Statistical analysis;Prevention and mitigation;Tagging;Cryptography;Artificial intelligence;Protection;Robots;Synthetic data;Artificial Intelligence;Data Leakage Prevention;Privacy;Synthetic Data;Data Security},
  doi={10.1109/AIRC64931.2025.11077549},
  ISSN={},
  month={May},}@ARTICLE{10198233,
  author={Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra},
  journal={IEEE Access}, 
  title={From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy}, 
  year={2023},
  volume={11},
  number={},
  pages={80218-80245},
  abstract={Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.},
  keywords={Chatbots;Artificial intelligence;Computer security;Hidden Markov models;Privacy;Ethics;Switches;Generative adversarial networks;Generative AI;GenAI and cybersecurity;ChatGPT;Google bard;cyber offense;cyber defense;ethical GenAI;privacy;artificial intelligence;cybersecurity;jailbreaking},
  doi={10.1109/ACCESS.2023.3300381},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10463452,
  author={Yoon, Namkyung and Kim, Hwangnam},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Pioneering AI in Chemical Data: New Frontline With GC- MS Generation}, 
  year={2024},
  volume={},
  number={},
  pages={826-831},
  abstract={The accurate detection and analysis of chemicals have become increasingly important for security and environmental monitoring with the integration of artificial intelligence (AI) methods gaining traction. However, the scarcity of certain chemicals poses significant challenges to the AI learning process. This paper presents a comprehensive AI approach and strategic direction for generating synthetic gas chromatography-mass spec-trometry (GC-MS) data for such limited-availability chemicals. We conduct exploratory data analysis (EDA) on GC-MS data and apply advanced AI-driven generative algorithms, with a focus on Variational Autoencoder (VAE) and Generative Adversarial Network (GAN), acknowledging the challenges faced by current AI technologies in learning from chemical data. Additionally, we introduce a secondary contribution by developing custom Python-based tools for 3D visualization of GC-MS data, enhancing intuitive understanding and analysis precision. Our findings offer new possibilities and directions for the expansive application of AI in chemical analysis.},
  keywords={Training;Three-dimensional displays;Data visualization;Generative adversarial networks;Data models;Security;Environmental monitoring;Data generation;Deep learning;Chemical data;Generative model},
  doi={10.1109/ICAIIC60209.2024.10463452},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{10511242,
  author={Bhile, Pranav Arvind and Maes, Pattie},
  booktitle={2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)}, 
  title={Understanding Structure Of LLM using Neural Cluster Knockout}, 
  year={2024},
  volume={},
  number={},
  pages={253-259},
  abstract={This research work presents a groundbreaking approach at the intersection of neuroscience and generative Artificial Intelligence (AI), focusing on the application of neuroscience techniques to neural networks, specifically Large Language Models (LLMs). Central to this study is the concept of ‘neural cluster knockout’ in LLMs, a method inspired by lesion studies in neuroscience involving the systematic removal of neuron clusters to decipher their role within the model. The research underscores the opaque nature of neural networks, particularly LLMs, which are often critiqued for their ‘black box’ operation. By adopting neuroscience principles, particularly lesion studies, this paper aims to illuminate the inner workings of neural networks, enhancing our understanding of their functionalities. This is crucial in an era increasingly reliant on AI in various sectors, where insights from this study could lead to the development of more efficient, transparent, and accountable AI systems. Methodologically, this study involved Principal Component Analysis (PCA) and neural cluster knockout through iterative zeroing, applied to the Large Language Model named LLaMA. This approach enabled the identification of significant neuron clusters and their functional impacts when deactivated. The results reveal both critical and redundant neurons within LLMs, demonstrating that some clusters are vital for accuracy, while others may impede efficiency or contribute to errors. This research contributes significantly to the AI field, offering a novel perspective on the intricate architecture of LLMs. It lays a foundation for future advancements in AI, envisioning refined and efficient LLMs capable of more accurate and reliable performance.},
  keywords={Neuroscience;Systematics;Neurons;Neural networks;Lesions;Reliability;Artificial intelligence;Large Language Model (LLM);Neural Cluster Knockout;Generative Artificial Intelligence (Gen AI);Increasing Accuracy and Efficiency in Generative Artificial Intelligence;Artificial Intelligence and Neuroscience Intersection;Large Language Model Optimization},
  doi={10.1109/ICICV62344.2024.00045},
  ISSN={},
  month={March},}@ARTICLE{11123168,
  author={Kim, Byeong-Je and Jeong, Seunghoo and Cho, Bong-Kyung and Chung, Ji-Bum},
  journal={IEEE Access}, 
  title={AI Governance in the Context of the EU AI Act}, 
  year={2025},
  volume={13},
  number={},
  pages={144126-144142},
  abstract={The rapid advancement of artificial intelligence (AI) has brought about significant societal changes, necessitating robust AI governance frameworks. This study analyzed the research trends in AI governance within the framework of the European Union Artificial Intelligence Act (EU AI Act). This study conducted a bibliometric analysis to examine the publications indexed in the Web of Science database. Our findings reveal that research on AI governance, particularly concerning AI systems regulated by the EU AI Act, remains relatively limited compared to the broader AI research landscape. Nonetheless, a growing interdisciplinary interest in AI governance is evident, with notable contributions from multi-disciplinary journals and open-access publications. Analysis of publications per country revealed that while the United States and China dominate AI governance research, European countries, along with the United Kingdom, also contribute significantly with a focus on specific systems restricted by the Act. Dominant research themes include ethical considerations, privacy concerns, and the growing impact of generative AI, such as ChatGPT. Notably, education, healthcare, and worker management are prominent application domains. Keyword network analysis highlights education, ethics, and ChatGPT as central keywords, underscoring the importance of these areas in current AI governance research. Subsequently, a comprehensive literature review was undertaken based on the bibliometric analysis findings to identify research trends, challenges, and insights within the categories of the EU AI Act. This review revealed critical gaps in research concerning regulated AI systems, highlighting the need for more focused research aligned with the Act’s regulatory framework. The findings provide valuable insights for researchers and policymakers, informing future research directions and contributing to developing comprehensive AI governance frameworks beyond the EU AI Act. Crucially, the study identifies a significant lag between AI technological advancement and the development of policy and regulation, especially concerning specific AI systems categorized as high-risk by the EU AI Act.},
  keywords={Artificial intelligence;Ethics;Regulation;Market research;Bibliometrics;Safety;Generative AI;Europe;Chatbots;Biological system modeling;Artificial intelligence;bibliometric analysis;EU AI Act;governance;research trend;Web of Science},
  doi={10.1109/ACCESS.2025.3598023},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10773519,
  author={Ersöz, Betül and Sağıroğlu, Şeref and Bülbül, Halil İbrahim},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Generative Artificial Intelligence Opportunities and Threats: Bibliometric Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study conducts a bibliometric analysis on 4,262 works published under the title “Generative Artificial Intelligence-GAI” between 2020 and 2024, sourced from Web of Science (WoS). The analysis covers keyword clouds, the most frequently used terms in article titles, types of publications, fields with the highest volume of publications. The research on GAI, a rapidly growing subfield of artificial intelligence (AI), is examined, the current state is critically analyzed, and recommendations are provided concerning the opportunities and threats in the responsible development of AI.},
  keywords={Computer science;Generative AI;Computational modeling;Bibliometrics;Robots;Research and development;Education;Data analysis;Chatbots;Python;generative artificial intelligence;GenAI;bibliometric analysis;artificial intelligence in education},
  doi={10.1109/UBMK63289.2024.10773519},
  ISSN={2521-1641},
  month={Oct},}@INPROCEEDINGS{10928174,
  author={Mansor, Mahayaudin M. and Ibrahim, Nurain and Radi, Noor Fadhilah Ahmad and Rahim, Nadirah Abdul and Yahaya, Syarul Heiry and Bakar, Mohd Aftar Abu and Zakaria, Roslinazairimah},
  booktitle={2024 IEEE International Conference on Computing (ICOCO)}, 
  title={Discrepancy and Thematic Bibliometric Analyses of the Remaining Limitations in Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={485-490},
  abstract={As artificial intelligence (AI) advances, it is essential to continuously comprehend its limitations to optimise the integration of AI into autonomous systems that empower humans. The first objective of this study is to highlight the key capabilities of both humans and AI, focusing on the differences and identifying limitations of AI from the literature. Through discrepancy analysis, this study uses a Venn diagram to visualise the remaining limitations of AI into five key domains: (i) emotional intelligence, (ii) consciousness and awareness, (iii) creative imagination, (iv) communication, and (v) ethical decision-making. Furthermore, this study employs thematic bibliometric analysis to provide a more detailed examination of each AI limitation as the second objective. This study has identified underdeveloped and emerging research themes with potential for future development, such as emotion recognition, human-computer interaction, digital health, and situational awareness, which may require further research. Additionally, this study commends the ongoing efforts to harness AI’s computational power and algorithmic innovations to enhance AI’s overall performance and applicability.},
  keywords={Visualization;Technological innovation;Ethics;Emotion recognition;Bibliometrics;Decision making;Focusing;Electronic healthcare;Object recognition;Artificial intelligence;traits discrepancy;Venn diagram;thematic map;ChatGPT;AI champion},
  doi={10.1109/ICOCO62848.2024.10928174},
  ISSN={},
  month={Dec},}@ARTICLE{10893883,
  author={Andriole, Stephen J.},
  journal={IT Professional}, 
  title={Artificial Intelligence Adoption Is Easy for Gigs, Start-Ups and Small Companies—But Not Mid-Sized and Large Enterprises}, 
  year={2025},
  volume={27},
  number={1},
  pages={11-13},
  abstract={AI, machine learning (ML) and generative AI (GenAI) platforms and tools provide an opportunity for smaller companies to solve business problems the same way large companies do—expect faster and cheaper. Gig workers, start-ups and small companies are in a strong position to exploit AI/ML/GenAI for competitive advantage—in many cases stronger positions than larger companies. C-suites in all-sized companies should be mindful of the opportunities and constraints around AI/ML/GenAI adoption.},
  keywords={Generative AI;Machine learning;Business;Artificial intelligence;Business intelligence;Competitive intelligence;Problem-solving;Management},
  doi={10.1109/MITP.2025.3529859},
  ISSN={1941-045X},
  month={Jan},}@INPROCEEDINGS{11134175,
  author={Pawan, Kommu Venkata and Singh, Manpreet},
  booktitle={2024 4th International Conference on Innovative Sustainable Computational Technologies (CISCT)}, 
  title={Liver Cancer Detection: A Review of Artificial Intelligence Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the most innovative ways to identify liver cancer is using deep learning. In medical image analysis, Convolutional Neural Networks (CNNs) reliably detect potential tumors in CT, MRI, and ultrasonography. The potential for improved patient outcomes and early detection is great with this research. The use of recurrent neural networks (RNNs) to interpret time-series data, including blood tests, offers an alternate method. RNNs may help with early risk prediction and personalized monitoring plan development. The interpretability of AI models, data quality, and seamless integration into healthcare processes are still problems, though. Advances in data synthesis, explainable AI (XAI), and userfriendly interfaces are addressing these challenges. Future prospects appear bright thanks to emerging technologies like Generative Adversarial Networks (GANs) and customized medical approaches that leverage several data sources. Collaboration between researchers, healthcare providers, and technology companies is necessary to accelerate innovation and ensure that it is more broadly available.},
  keywords={Deep learning;Liver cancer;Recurrent neural networks;Explainable AI;Medical services;Ultrasonography;Generative adversarial networks;Convolutional neural networks;Biomedical imaging;Tumors;Deep learning;Time-series Data;Medical Imaging;Explainable Artificial Intelligence (XAI);Recurrent Neural Networks (RNNs);Convolutional Neural Networks (CNNs);Individualized Medicine;Generative Adversarial Networks (GANs)},
  doi={10.1109/CISCT62494.2024.11134175},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10939868,
  author={Hu, Yongchen},
  booktitle={2024 International Conference on Distributed Systems, Computer Networks and Cybersecurity (ICDSCNC)}, 
  title={An Automatic Generation of Poetry using Generative Pre-Trained Transformer with Fine Tuning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In current trends, poetry is a creative expression of thoughts and emotions which manifesting as sequences of words to express ideas in an imaginative style for Automatic generation of poetry. Natural Language Generation (NLG) and generative Artificial Intelligence (AI) generally create a new poem. But the generative AI has lack of poem originality, has limited content which is failed in generating deeper information on the related topic and heavily struggling to create the new concepts with sequential words. To overcome these issues, the model of Generative Pre-trained Transformer 2 with fine tuning (GPT-2-FT) is proposed which is coherent for adapting various forms and contexts to avoid nonsensical sequence of text words. Initially, Poem Generation dataset is used, then in preprocessing, input tokens are divided into different individual words and gives it as input to training words. The proposed GPT-2-FT gives an accurate value and also handles the emotions of poem by Generative Adversarial Network (GAN) which including generator and discriminator. The proposed GPT-2-FT gives improved results in terms of Coherence, accuracy and fluency which values are given by (8.777), (0.998) and (0.975) respectively than existing Bilingual Evaluation Understudy (BLEU) model.},
  keywords={Analytical models;Accuracy;Generative AI;Natural language generation;Coherence;Writing;Generative adversarial networks;Transformers;Generators;Tuning;automatic generation of poetry;fine tuning;generative adversarial network;generative pre-trained transformer 2;natural language generation},
  doi={10.1109/ICDSCNC62492.2024.10939868},
  ISSN={},
  month={Sep.},}@ARTICLE{10591982,
  author={Awaisi, Kamran Sattar and Ye, Qiang and Sampalli, Srinivas},
  journal={IEEE Access}, 
  title={A Survey of Industrial AIoT: Opportunities, Challenges, and Directions}, 
  year={2024},
  volume={12},
  number={},
  pages={96946-96996},
  abstract={Internet of Things (IoT) is an important technology employed in a variety of different applications, such as transportation, healthcare, and manufacturing. In recent years, the number of IoT devices deployed globally has been increasing at a rapid pace and is estimated to reach 20 billion by the end of 2025. In modern industry, IoT plays a pivotal role by monitoring the condition of industrial machines and, consequently, improving the efficiency of industrial processes. To optimize the efficiency of industrial IoT applications, various Artificial Intelligence (AI) techniques have been adopted, leading to a new computing paradigm, namely, Industrial Artificial Intelligence of Things (i.e. Industrial AIoT). In this paper, we describe the challenges to tackle and the opportunities to explore in Industrial AIoT. Specifically, we first review the use of state-of-the-art AI methods in Industrial AIoT applications, with a focus on Deep Learning (DL) and Machine Learning (ML) techniques. Thereafter, we present a series of important applications of Industrial AIoT. The key challenges associated with the implementation of Industrial AIoT applications are also discussed. In addition, the societal and economic impacts of Industrial AIoT are briefly described. Finally, we outline the future research directions in Industrial AIoT, which should be further investigated to fully utilize the potential of this innovative technology.},
  keywords={Artificial intelligence;Industrial Internet of Things;Sensors;Industries;Monitoring;Logic gates;Internet of Things;Machine learning;Deep learning;Internet of Things (IoT);industrial internet of things (IIoT);artificial intelligence (AI);artificial intelligence of things (AIoT);industrial AIoT;machine learning (ML);deep learning (DL)},
  doi={10.1109/ACCESS.2024.3426279},
  ISSN={2169-3536},
  month={},}@INBOOK{10950937,
  author={Singh, Shiv},
  booktitle={Marketing with AI For Dummies}, 
  title={A Brief History of AI}, 
  year={2025},
  volume={},
  number={},
  pages={7-21},
  abstract={Summary <p>Modern science and technology have realized some of the mythological concepts through recent advancements. This chapter introduces the readers to those advancements, including the Turing test, machine learning, expert systems, and generative artificial intelligence (AI). Turing's test proposed that a human evaluator assess dialogues between a human and a machine that was designed to generate human&#x2010;like responses. Computers have advanced by leaps and bounds since the time that Alan Turing first proposed the Turing test. Following the Dartmouth Conference, two key subfields emerged that became the cornerstones of artificial intelligence &#x2014; machine learning and expert systems. The 1980s stand as a critical decade in the development of AI, characterized by groundbreaking advancements in various subfields, especially in machine learning, neural networks, and natural language processing. The advent of deep learning has significantly elevated the capabilities and accuracy of AI systems.</p>},
  keywords={Artificial intelligence;History;Technological innovation;Calculators;Virtual assistants;Shape;Natural languages;Internet;Human intelligence;Computer science},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394237210},
  url={https://ieeexplore-ieee-org.crai.referencistas.com/document/10950937},}@INPROCEEDINGS{11154481,
  author={Nam, Ji Hee and Kwon, Hun-Yeong},
  booktitle={2025 IEEE/ACIS 23rd International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={The Necessity and Development Direction of Military AI Utilization}, 
  year={2025},
  volume={},
  number={},
  pages={472-475},
  abstract={The role of artificial intelligence (AI) in military decision-making is becoming increasingly important, and it can enhance efficiency and accuracy while strengthening safety. This study analyzes the potential application of military AI and the major challenges that arise from it and suggests solutions and policy considerations. AI has potential applications in various fields such as reconnaissance, combat support, cybersecurity, and military training, and this technology can play a key role in securing military superiority. However, military AI faces problems such as lack of transparency, vulnerability to adversarial attacks, lack of data, and lack of legal regulations and international cooperation. To solve these problems, it is essential to develop explainable AI technology, establish data supplementation strategies, establish international ethical standards and legal regulations, and strengthen international cooperation. This paper discusses the application and development direction of military AI and seeks ways for AI technology to be used responsibly. Through this, we hope that AI technology can contribute to promoting peace and security.},
  keywords={Training;Law;Explainable AI;Reconnaissance;Regulation;Safety;Artificial intelligence;Standards;Faces;Software engineering;Military AI;Military Strategies;International Cooperation and Regulation},
  doi={10.1109/SERA65747.2025.11154481},
  ISSN={2770-8209},
  month={May},}@INPROCEEDINGS{10056645,
  author={Kuzlu, Murat and Catak, Ferhat Ozgur and Sarp, Salih and Cali, Umit and Gueler, Oezguer},
  booktitle={2022 IEEE Future Networks World Forum (FNWF)}, 
  title={A Streamlit-based Artificial Intelligence Trust Platform for Next-Generation Wireless Networks}, 
  year={2022},
  volume={},
  number={},
  pages={94-97},
  abstract={With the rapid development and integration of artificial intelligence (AI) methods in next-generation networks (NextG), AI algorithms have provided significant advantages for NextG in terms of frequency spectrum usage, bandwidth, latency, and security. A key feature of NextG is the integration of AI, i.e., self-learning architecture based on self-supervised algorithms, to improve the performance of the network. A secure AI-powered structure is also expected to protect N extG networks against cyber-attacks. However, AI itself may be attacked, i.e., model poisoning targeted by attackers, and it results in cybersecurity violations. This paper proposes an AI trust platform using Streamlit for N extG networks that allows researchers to evaluate, defend, certify, and verify their AI models and applications against adversarial threats of evasion, poisoning, extraction, and interference.},
  keywords={Training;Wireless networks;Interference;Robustness;Libraries;Sensors;Planning;Artificial Intelligence;Cybersecurity;Next Gen-eration Networks;Streamlit},
  doi={10.1109/FNWF55208.2022.00025},
  ISSN={2770-7679},
  month={Oct},}@INPROCEEDINGS{10528637,
  author={Wang, Weiqi and Huang, Yi and Miao, Han},
  booktitle={2023 7th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Research on Artistic Style Transfer of Chinese Painting Based on Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={986-991},
  abstract={In order to further improve the artistic style transfer effect of traditional painting, this paper proposes an artistic style transfer method of Chinese painting based on generative adversarial network. Where, the cyclic generative adversarial network (CycleGAN) is selected as the basic style transfer algorithm, and the loss function in the network is improved, so as to further enhance the style transfer effect. The experimental results show that compared with the CycleGAN before improvement, the improved CycleGAN has better stability. Compared with other transfer algorithms, the designed Chinese painting artistic style transfer algorithm based on improved CycleGAN has better transfer effect, and the FID score, PSNR and SSIM of the designed algorithm are 162.09, 99.61 and 0.7, respectively. In conclusion, the transfer effect of the designed style transfer algorithm is good, and the designed style transfer algorithm can be applied to the actual Chinese painting artistic style transfer with high reliability.},
  keywords={Generative adversarial networks;Reliability engineering;Artificial intelligence;Optimization;Painting;style transfer;generative adversarial network;algorithm improvement;feature constraint},
  doi={10.1109/ACAIT60137.2023.10528637},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10548425,
  author={Ye, Wanqi and Zhou, Lei and Mo, Jiayong and Zeng, Zifeng},
  booktitle={2024 Third International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)}, 
  title={Exploring Automated Defense Technology of Artificial Intelligence in Network Security}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={How to address the increasing number of network security threats and attacks? Traditional manual defense methods are no longer able to cope with them. This article provides an overview of the automated defense technology of artificial intelligence (AI) in network security. This article introduces the application fields of AI in network security, including intrusion detection and prevention, malicious code detection, and network traffic analysis. Then, a Support Vector Machine (SVM) model is proposed to achieve automated defense of network security. SVM divides traffic into normal and malicious based on the characteristics of network traffic, thereby achieving intrusion detection and identification of abnormal behavior. After experimental testing, the attack detection rate of the method in this article is between 94% -99%, which can effectively detect malicious attacks.},
  keywords={Support vector machines;Privacy;Intrusion detection;Telecommunication traffic;Manuals;Network security;Robustness;automated defense technology;network security;artificial intelligence;SVM},
  doi={10.1109/ICDCECE60827.2024.10548425},
  ISSN={},
  month={April},}@INPROCEEDINGS{10690690,
  author={S, Murugun and Haniah, Sheikh and Koti, Shambhavi M and Sahani, Saurav and S N, Shekhar},
  booktitle={2024 Second International Conference on Advances in Information Technology (ICAIT)}, 
  title={A Review on Phishing Threats and Data Securityin Online Trading Systems using Artificial Intelligence Techniques}, 
  year={2024},
  volume={1},
  number={},
  pages={1-6},
  abstract={Phishing threats pose significant risks to online trading systems, threatening the security and integrity of financial transactions. In this paper, we present a comprehensive review of phishing threats and data securityin online trading systems, focusing on the application of artificial intelligence (AI) techniques for detection and prevention. We discuss the evolving landscape of online trading, highlighting the risks associated with technological disruptions, malware, and phishing attacks. The paper explores various AI-based approaches, including machine learning and natural language processing, for detecting and mitigating phishing threats in real time. Additionally, we review recent studies on phishing classification techniques, AI-enabled detection mechanisms, cyber security awareness training, and deep learning-based approaches for phishing detection. Through a systematic review of existing literature, we identify challenges such as data availability, model interpretability, and scalability, and propose future research directions to enhance cyber security defenses against evolving phishing threats in online trading systems. Furthermore, we are Enhancing user education and awareness which plays a crucial role in effectively combating phishing attacks. Also, highlighting the need for collaboration between industry stakeholders, policymakers, and researchers to develop effective strategies for protecting online traders and investors from financial fraud and identity theft.},
  keywords={Training;Industries;Phishing;Identity theft;Scalability;Collaboration;Finance;Phishing Threats;Data Security;Online Trading systems;Artificial Intelligence;Machine Learning;CyberSecurity},
  doi={10.1109/ICAIT61638.2024.10690690},
  ISSN={},
  month={July},}@INPROCEEDINGS{11011809,
  author={V P, Shivaani and G, Muthupandi and Pavithra, S.},
  booktitle={2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)}, 
  title={A Review of Generative AI in Recommendation Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Traditional machine learning algorithms have paved the way for more sophisticated models mainly in the field of Gen AI. This review compares how Gen AI is used in recommendation systems to traditional AI methods and the application of both in various fields. Generative AI has transformed the systems for recommendation by correcting the flaws of conventional machine learning approaches. This review compares the use of Gen AI and conventional AI in RS throughout various fields, with a focus on GANs and VAEs. These generative models indicate their capabilities and challenges involving low data, cold start, and lack of diversity in recommendations. They also show potential limitations for further research. The report outlines recent works to represent how Gen AI enhances RS performance traces key trends, and addresses relevant emerging concerns with reliability and ethics. The results highlight hybrid approaches, promising further developments of the effective and flexible RSs. To conclude, the paper advocates for further research to be performed.},
  keywords={Sentiment analysis;Machine learning algorithms;Generative AI;Reviews;Machine learning;Logic gates;Market research;Reliability;Artificial intelligence;Recommender systems;Recommendation Systems;Collaborative Filtering;Content-based Filtering;Hybrid Approach;Generative Adversarial Networks (GANs)},
  doi={10.1109/ICDSAAI65575.2025.11011809},
  ISSN={},
  month={March},}@INPROCEEDINGS{10911263,
  author={Rathore, Rachna and Sharma, Pranay and Sharma, Umesh Chandra and Jenasamanta, Abhinash and Shilpa, S. and Sahu, Praveen Kumar},
  booktitle={2024 4th International Conference on Advancement in Electronics & Communication Engineering (AECE)}, 
  title={Game Theory Applications in AI}, 
  year={2024},
  volume={},
  number={},
  pages={255-260},
  abstract={The convergence of artificial intelligence (AI) and game theory presents intriguing research and application opportunities. This overview explores the fundamental concepts of game theory and its influence on AI systems and techniques. Various AI applications of game theory are examined, including mechanism design, auctions, adversarial machine learning, reinforcement learning, and multi-agent systems. Additionally, we delve into game-theoretic methods utilized in AI, such as cooperative game theory, Nash equilibria computation, and the minimax algorithm. Through case studies and comparative analysis, we assess the strengths, weaknesses, current challenges, and future directions in this field. The aim of this review is to illuminate the synergies between game theory and artificial intelligence.},
  keywords={Technological innovation;Ethics;Machine learning algorithms;Reviews;Mechanism design;Collaboration;Reinforcement learning;Adversarial machine learning;Artificial intelligence;Game theory;Game Theory;Artificial Intelligence;Multi- Agent Systems;Reinforcement Learning;Adversarial Machine Learning;Auctions;Mechanism Design;Minimax Algorithm;Nash Equilibria;Cooperative Game Theory},
  doi={10.1109/AECE62803.2024.10911263},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8718231,
  author={Sadeghi, Koosha and Banerjee, Ayan and Gupta, Sandeep K. S.},
  booktitle={2019 IEEE International Conference On Artificial Intelligence Testing (AITest)}, 
  title={An Analytical Framework for Security-Tuning of Artificial Intelligence Applications Under Attack}, 
  year={2019},
  volume={},
  number={},
  pages={111-118},
  abstract={Machine Learning (ML) algorithms, as the core technology in Artificial Intelligence (AI) applications, such as self-driving vehicles, make important decisions by performing a variety of data classification or prediction tasks. Attacks on data or algorithms in AI applications can lead to misclassification or misprediction, which can fail the applications. For each dataset separately, the parameters of ML algorithms should be tuned to reach a desirable classification or prediction accuracy. Typically, ML experts tune the parameters empirically, which can be time consuming and does not guarantee the optimal result. To this end, some research suggests an analytical approach to tune the ML parameters for maximum accuracy. However, none of the works consider the ML performance under attack in their tuning process. This paper proposes an analytical framework for tuning the ML parameters to be secure against attacks, while keeping its accuracy high. The framework finds the optimal set of parameters by defining a novel objective function, which takes into account the test results of both ML accuracy and its security against attacks. For validating the framework, an AI application is implemented to recognize whether a subject's eyes are open or closed, by applying k-Nearest Neighbors (kNN) algorithm on her Electroencephalogram (EEG) signals. In this application, the number of neighbors (k) and the distance metric type, as the two main parameters of kNN, are chosen for tuning. The input data perturbation attack, as one of the most common attacks on ML algorithms, is used for testing the security of the application. Exhaustive search approach is used to solve the optimization problem. The experiment results show k = 43 and cosine distance metric is the optimal configuration of kNN for the EEG dataset, which leads to 83.75% classification accuracy and reduces the attack success rate to 5.21%.},
  keywords={Security;Artificial intelligence;Perturbation methods;Tuning;Prediction algorithms;Optimization;Testing;artificial intelligence;machine learning;security;perturbation attack;parameters tuning;optimization},
  doi={10.1109/AITest.2019.00012},
  ISSN={},
  month={April},}
